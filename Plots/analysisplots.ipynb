{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Popularity Bias Reproduction Results\n",
    "\n",
    "This notebook analyzes the consolidated results from the popularity bias reproduction study, generating plots and tables to support the findings discussed in the main report. It focuses on visualizing the impact of domain, evaluation strategy, algorithm, and user grouping method (including the novel 'NicheConsumptionRate') on %Î”GAP and NDCG@10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output will be saved to: c:\\Users\\Shreyash\\Desktop\\Files\\Work\\cs516\\516 Project\\Plots\\analysis_plots_tables_v2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as mcolors\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "# Ignore common warnings (optional)\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "\n",
    "# Display options for pandas\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "# --- Configuration ---\n",
    "CSV_FILE_PATH = 'consolidated_results.csv'\n",
    "OUTPUT_DIR = 'analysis_plots_tables_v2' # Changed output dir name\n",
    "SIGNIFICANCE_THRESHOLD = 0.05\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "print(f\"Output will be saved to: {os.path.abspath(OUTPUT_DIR)}\")\n",
    "\n",
    "# Seaborn style\n",
    "sns.set_theme(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_conceptual_group(row):\n",
    "    \"\"\"Maps specific user groups from different notions to conceptual groups.\"\"\"\n",
    "    pop_notion = row['popularity_notion']\n",
    "    user_group = row['user_group']\n",
    "\n",
    "    if pop_notion in ['pop_one', 'pop_two']:\n",
    "        if user_group == 'low':\n",
    "            return 'Niche-Oriented'\n",
    "        elif user_group == 'med':\n",
    "            return 'Diverse'\n",
    "        elif user_group == 'high':\n",
    "            return 'Blockbuster-Oriented'\n",
    "    elif pop_notion == 'pop_four':\n",
    "        if user_group == 'high': # High niche consumption rate -> Niche-Oriented\n",
    "            return 'Niche-Oriented'\n",
    "        elif user_group == 'med':\n",
    "            return 'Diverse'\n",
    "        elif user_group == 'low': # Low niche consumption rate -> Blockbuster-Oriented\n",
    "            return 'Blockbuster-Oriented'\n",
    "    return 'Unknown' # Should not happen with valid data\n",
    "\n",
    "def map_descriptive_names(df):\n",
    "    \"\"\"Maps codes to more descriptive names for plots.\"\"\"\n",
    "    strategy_map = {\n",
    "        'eva_two': 'UserTest',\n",
    "        'eva_three': 'TrainItems'\n",
    "    }\n",
    "    notion_map = {\n",
    "        'pop_one': 'PopularPercentage',\n",
    "        'pop_two': 'AveragePopularity',\n",
    "        'pop_four': 'NicheConsumptionRate'\n",
    "    }\n",
    "    # Use .get with default to avoid errors if unexpected values appear\n",
    "    df['eval_strategy_desc'] = df['evaluation_strategy'].apply(lambda x: strategy_map.get(x, x))\n",
    "    df['pop_notion_desc'] = df['popularity_notion'].apply(lambda x: notion_map.get(x, x))\n",
    "    return df\n",
    "\n",
    "def highlight_significant(val):\n",
    "    \"\"\"Highlights p-values below the significance threshold for display.\"\"\"\n",
    "    if pd.isna(val):\n",
    "        return ''\n",
    "    # Use background color for better visibility in tables\n",
    "    bgcolor = 'background-color: yellow' if val < SIGNIFICANCE_THRESHOLD else ''\n",
    "    return bgcolor\n",
    "\n",
    "def plot_faceted_grouped_bar(data, y_metric, title_prefix, filename_prefix):\n",
    "    \"\"\"Generates faceted grouped bar charts (Metric by User Group within each notion/strategy).\"\"\"\n",
    "    if data.empty:\n",
    "        print(f\"Skipping faceted plot for {y_metric} - no data.\")\n",
    "        return\n",
    "    try:\n",
    "        # Ensure categorical types for consistent ordering\n",
    "        data['algorithm'] = pd.Categorical(data['algorithm'], categories=sorted(data['algorithm'].unique()), ordered=True)\n",
    "        data['user_group'] = pd.Categorical(data['user_group'], categories=['low', 'med', 'high'], ordered=True)\n",
    "\n",
    "        g = sns.catplot(\n",
    "            data=data,\n",
    "            x='algorithm',\n",
    "            y=y_metric,\n",
    "            hue='user_group',\n",
    "            col='eval_strategy_desc',\n",
    "            row='pop_notion_desc',\n",
    "            kind='bar',\n",
    "            sharey=False, # Allow different y-axis scales\n",
    "            aspect=1.5,\n",
    "            height=4,\n",
    "            palette='viridis',\n",
    "            errorbar=None # Omit error bars for clarity, or use ('ci', 95)\n",
    "            # order=sorted(data['algorithm'].unique()), # Redundant with categorical\n",
    "            # hue_order=['low', 'med', 'high'] # Redundant with categorical\n",
    "        )\n",
    "        g.fig.suptitle(f'{title_prefix}: {y_metric} by User Group (Facets: Pop Notion / Eval Strategy)', y=1.03)\n",
    "        g.set_axis_labels(\"Algorithm\", y_metric)\n",
    "        g.set_titles(row_template=\"{row_name}\", col_template=\"{col_name}\")\n",
    "        g.tick_params(axis='x', rotation=45)\n",
    "        plt.tight_layout(rect=[0, 0, 1, 1]) # Adjust layout\n",
    "        filepath = os.path.join(OUTPUT_DIR, f'{filename_prefix}_{y_metric}_faceted.png')\n",
    "        plt.savefig(filepath, bbox_inches='tight')\n",
    "        print(f\"Saved faceted bar chart to {filepath}\")\n",
    "        # plt.show()\n",
    "        plt.close(g.fig) # Close the specific figure\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating faceted bar chart for {y_metric}: {e}\")\n",
    "\n",
    "def plot_comparative_grouped_bar(data, y_metric, title_prefix, filename_prefix):\n",
    "    \"\"\"Generates comparative grouped bar charts (Metric by Pop Notion for each conceptual group).\"\"\"\n",
    "    conceptual_groups = ['Niche-Oriented', 'Diverse', 'Blockbuster-Oriented']\n",
    "    for concept_group in conceptual_groups:\n",
    "        df_filtered = data[data['conceptual_group'] == concept_group].copy()\n",
    "        if df_filtered.empty:\n",
    "            print(f\"Skipping comparative plot for {concept_group} - no data.\")\n",
    "            continue\n",
    "        try:\n",
    "            df_filtered['algorithm'] = pd.Categorical(df_filtered['algorithm'], categories=sorted(df_filtered['algorithm'].unique()), ordered=True)\n",
    "            df_filtered['pop_notion_desc'] = pd.Categorical(df_filtered['pop_notion_desc'], categories=sorted(df_filtered['pop_notion_desc'].unique()), ordered=True)\n",
    "\n",
    "            g = sns.catplot(\n",
    "                data=df_filtered,\n",
    "                x='algorithm',\n",
    "                y=y_metric,\n",
    "                hue='pop_notion_desc', # Compare the grouping methods\n",
    "                col='eval_strategy_desc',\n",
    "                row='domain',\n",
    "                kind='bar',\n",
    "                sharey=False,\n",
    "                aspect=1.5,\n",
    "                height=4,\n",
    "                palette='magma',\n",
    "                errorbar=None\n",
    "                # order=sorted(df_filtered['algorithm'].unique()), # Redundant\n",
    "                # hue_order=sorted(df_filtered['pop_notion_desc'].unique()) # Redundant\n",
    "            )\n",
    "            g.fig.suptitle(f'{title_prefix}: {y_metric} Comparison for {concept_group} Users', y=1.03)\n",
    "            g.set_axis_labels(\"Algorithm\", y_metric)\n",
    "            g.set_titles(row_template=\"{row_name}\", col_template=\"{col_name}\")\n",
    "            g.tick_params(axis='x', rotation=45)\n",
    "            plt.tight_layout(rect=[0, 0, 1, 1])\n",
    "            filepath = os.path.join(OUTPUT_DIR, f'{filename_prefix}_{y_metric}_compare_{concept_group}.png')\n",
    "            plt.savefig(filepath, bbox_inches='tight')\n",
    "            print(f\"Saved comparative bar chart to {filepath}\")\n",
    "            # plt.show()\n",
    "            plt.close(g.fig) # Close the specific figure\n",
    "        except Exception as e:\n",
    "            print(f\"Error generating comparative bar chart for {concept_group} / {y_metric}: {e}\")\n",
    "\n",
    "\n",
    "def create_summary_table(data, metric_value_col, filename):\n",
    "    \"\"\"Creates and saves a pivot table summarizing the metric.\"\"\"\n",
    "    if data.empty:\n",
    "        print(f\"Skipping summary table {filename} - no data.\")\n",
    "        return None\n",
    "    try:\n",
    "        pivot = pd.pivot_table(\n",
    "            data,\n",
    "            index='algorithm',\n",
    "            columns=['domain', 'eval_strategy_desc', 'pop_notion_desc', 'user_group'],\n",
    "            values=metric_value_col\n",
    "        )\n",
    "        print(f\"\\n--- Summary Table: {metric_value_col} --- created (saving to file).\")\n",
    "        # Use display(pivot.style...) in notebook if desired\n",
    "        filepath = os.path.join(OUTPUT_DIR, filename)\n",
    "        pivot.to_csv(filepath)\n",
    "        print(f\"Saved table to {filepath}\")\n",
    "        return pivot\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating pivot table for {metric_value_col}: {e}\")\n",
    "        return None\n",
    "\n",
    "def create_ttest_table(data, filename):\n",
    "    \"\"\"Creates and saves a pivot table for T-test p-values with highlighting.\"\"\"\n",
    "    if data.empty:\n",
    "        print(f\"Skipping t-test table {filename} - no data.\")\n",
    "        return None\n",
    "    try:\n",
    "        pivot = pd.pivot_table(\n",
    "            data,\n",
    "            index='algorithm',\n",
    "            columns=['domain', 'eval_strategy_desc', 'pop_notion_desc', 'comparison_group'],\n",
    "            values='p_value'\n",
    "        )\n",
    "        metric_name = data['metric_type'].iloc[0].replace('_TTEST','') if not data.empty else 'Unknown Metric'\n",
    "        print(f\"\\n--- T-Test p-value Table: {metric_name} --- created (saving to Excel).\")\n",
    "        # Save styled excel\n",
    "        excel_filepath = os.path.join(OUTPUT_DIR, filename.replace('.csv','.xlsx'))\n",
    "        # Use Styler.applymap which is deprecated but widely compatible, or Styler.map for newer pandas\n",
    "        try: # Try newer Styler.map first\n",
    "          pivot.style.format(\"{:.4f}\").map(highlight_significant).to_excel(excel_filepath, engine='openpyxl')\n",
    "        except AttributeError:\n",
    "          # Fallback to older Styler.applymap\n",
    "           pivot.style.format(\"{:.4f}\").applymap(highlight_significant).to_excel(excel_filepath, engine='openpyxl')\n",
    "        print(f\"Saved styled Excel table to {excel_filepath}\")\n",
    "        return pivot\n",
    "    except ImportError:\n",
    "         print(f\"Error: 'openpyxl' required for Excel export. Install it (`pip install openpyxl`) and try again.\")\n",
    "         # Save as CSV as fallback\n",
    "         csv_filepath = os.path.join(OUTPUT_DIR, filename)\n",
    "         try:\n",
    "            pivot.to_csv(csv_filepath)\n",
    "            print(f\"Saved unstyled CSV table as fallback to {csv_filepath}\")\n",
    "         except Exception as e_csv:\n",
    "             print(f\"Error saving T-test pivot table as CSV: {e_csv}\")\n",
    "         return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating or saving T-test pivot table: {e}\")\n",
    "        return None\n",
    "\n",
    "def plot_bias_accuracy_scatter(df_merged, filename_prefix):\n",
    "    \"\"\"Plots %Î”GAP vs NDCG@10.\"\"\"\n",
    "    if df_merged.empty:\n",
    "        print(\"Skipping Bias vs Accuracy scatter plot - no merged data.\")\n",
    "        return\n",
    "    try:\n",
    "        df_merged['algorithm'] = pd.Categorical(df_merged['algorithm'], categories=sorted(df_merged['algorithm'].unique()), ordered=True)\n",
    "        df_merged['conceptual_group'] = pd.Categorical(df_merged['conceptual_group'], categories=['Niche-Oriented', 'Diverse', 'Blockbuster-Oriented'], ordered=True)\n",
    "\n",
    "        g = sns.relplot(\n",
    "            data=df_merged,\n",
    "            x='value_gap',\n",
    "            y='value_ndcg',\n",
    "            hue='algorithm',\n",
    "            style='conceptual_group', # Style distinguishes conceptual groups\n",
    "            col='eval_strategy_desc',\n",
    "            row='pop_notion_desc',\n",
    "            kind='scatter',\n",
    "            facet_kws={'sharex': False, 'sharey': False}, # Axes can vary\n",
    "            aspect=1.5,\n",
    "            height=4,\n",
    "            palette='tab10', # Use a distinct palette for algorithms\n",
    "            col_order = sorted(df_merged['eval_strategy_desc'].unique()),\n",
    "            row_order = sorted(df_merged['pop_notion_desc'].unique()),\n",
    "            style_order = ['Niche-Oriented', 'Diverse', 'Blockbuster-Oriented'],\n",
    "            s=50 # Adjust point size\n",
    "        )\n",
    "        g.fig.suptitle('%Î”GAP vs NDCG@10 (Hue: Algorithm, Style: Conceptual Group)', y=1.03)\n",
    "        g.set_axis_labels(\"%Î”GAP\", \"NDCG@10\")\n",
    "        g.set_titles(row_template=\"{row_name}\", col_template=\"{col_name}\")\n",
    "        plt.tight_layout(rect=[0, 0, 1, 1])\n",
    "        filepath = os.path.join(OUTPUT_DIR, f'{filename_prefix}_bias_vs_accuracy_scatter.png')\n",
    "        plt.savefig(filepath, bbox_inches='tight')\n",
    "        print(f\"Saved scatter plot to {filepath}\")\n",
    "        # plt.show()\n",
    "        plt.close(g.fig)\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating scatter plot: {e}\")\n",
    "\n",
    "\n",
    "def plot_fairness_gap(df_diff, diff_metric_col, y_label, title_suffix, filename_prefix):\n",
    "    \"\"\"Plots the calculated fairness gap (difference between groups).\"\"\"\n",
    "    if df_diff.empty or diff_metric_col not in df_diff.columns:\n",
    "        print(f\"Skipping Fairness Gap plot for {y_label} - missing data or column.\")\n",
    "        return\n",
    "    try:\n",
    "        df_diff['algorithm'] = pd.Categorical(df_diff['algorithm'], categories=sorted(df_diff['algorithm'].unique()), ordered=True)\n",
    "        df_diff['pop_notion_desc'] = pd.Categorical(df_diff['pop_notion_desc'], categories=sorted(df_diff['pop_notion_desc'].unique()), ordered=True)\n",
    "\n",
    "        g = sns.catplot(\n",
    "            data=df_diff,\n",
    "            x='algorithm',\n",
    "            y=diff_metric_col,\n",
    "            hue='pop_notion_desc', # Compare how notions measure the gap\n",
    "            col='eval_strategy_desc',\n",
    "            row='domain',\n",
    "            kind='bar',\n",
    "            sharey=True, # Keep y-axis same for direct comparison of gap magnitude\n",
    "            aspect=1.5,\n",
    "            height=4,\n",
    "            palette='crest',\n",
    "            errorbar=None\n",
    "            # order=sorted(df_diff['algorithm'].unique()) # Redundant\n",
    "        )\n",
    "        g.fig.suptitle(f'Fairness Gap Comparison ({title_suffix})', y=1.03)\n",
    "        g.set_axis_labels(\"Algorithm\", y_label)\n",
    "        g.set_titles(row_template=\"{row_name}\", col_template=\"{col_name}\")\n",
    "        g.tick_params(axis='x', rotation=45)\n",
    "        # Add zero line using map\n",
    "        g.map(plt.axhline, y=0, color='grey', linestyle='--', linewidth=0.8) \n",
    "        plt.tight_layout(rect=[0, 0, 1, 1])\n",
    "        filepath = os.path.join(OUTPUT_DIR, f'{filename_prefix}_fairness_gap.png')\n",
    "        plt.savefig(filepath, bbox_inches='tight')\n",
    "        print(f\"Saved fairness gap plot to {filepath}\")\n",
    "        # plt.show()\n",
    "        plt.close(g.fig)\n",
    "    except Exception as e:\n",
    "         print(f\"Error generating fairness gap plot for {y_label}: {e}\")\n",
    "\n",
    "def plot_strategy_impact_delta(df_diff, diff_metric_col, y_label, title_suffix, filename_prefix):\n",
    "    \"\"\"Plots the delta change in metric due to evaluation strategy.\"\"\"\n",
    "    if df_diff.empty or diff_metric_col not in df_diff.columns:\n",
    "        print(f\"Skipping Strategy Impact plot for {y_label} - missing data or column.\")\n",
    "        return\n",
    "    try:\n",
    "        df_diff['algorithm'] = pd.Categorical(df_diff['algorithm'], categories=sorted(df_diff['algorithm'].unique()), ordered=True)\n",
    "        df_diff['conceptual_group'] = pd.Categorical(df_diff['conceptual_group'], categories=['Niche-Oriented', 'Diverse', 'Blockbuster-Oriented'], ordered=True)\n",
    "\n",
    "        g = sns.catplot(\n",
    "            data=df_diff,\n",
    "            x='algorithm',\n",
    "            y=diff_metric_col,\n",
    "            hue='conceptual_group', # Show impact per conceptual group\n",
    "            col='pop_notion_desc',\n",
    "            row='domain',\n",
    "            kind='bar',\n",
    "            sharey=True,\n",
    "            aspect=1.5,\n",
    "            height=4,\n",
    "            palette='flare',\n",
    "            errorbar=None\n",
    "            # order=sorted(df_diff['algorithm'].unique()), # Redundant\n",
    "            # hue_order=['Niche-Oriented', 'Diverse', 'Blockbuster-Oriented'] # Redundant\n",
    "        )\n",
    "        g.fig.suptitle(f'Evaluation Strategy Impact ({title_suffix}: TrainItems - UserTest)', y=1.03)\n",
    "        g.set_axis_labels(\"Algorithm\", y_label)\n",
    "        g.set_titles(row_template=\"{row_name}\", col_template=\"{col_name}\")\n",
    "        g.tick_params(axis='x', rotation=45)\n",
    "        g.map(plt.axhline, y=0, color='grey', linestyle='--', linewidth=0.8)\n",
    "        plt.tight_layout(rect=[0, 0, 1, 1])\n",
    "        filepath = os.path.join(OUTPUT_DIR, f'{filename_prefix}_strategy_impact.png')\n",
    "        plt.savefig(filepath, bbox_inches='tight')\n",
    "        print(f\"Saved strategy impact plot to {filepath}\")\n",
    "        # plt.show()\n",
    "        plt.close(g.fig)\n",
    "    except Exception as e:\n",
    "         print(f\"Error generating strategy impact plot for {y_label}: {e}\")\n",
    "\n",
    "def plot_combined_metric_bar(df_merged, filename_prefix):\n",
    "    \"\"\"Plots NDCG as bar height and colors by %Î”GAP.\"\"\"\n",
    "    if df_merged.empty:\n",
    "        print(\"Skipping Combined Metric plot - no merged data.\")\n",
    "        return\n",
    "    try:\n",
    "        # Determine global min/max for %Î”GAP for consistent color mapping\n",
    "        vmin = df_merged['value_gap'].min()\n",
    "        vmax = df_merged['value_gap'].max()\n",
    "        # Ensure vmin and vmax are different for norm, handle case where all values are same\n",
    "        if vmin == vmax:\n",
    "            vmin -= 1 # Add a small range\n",
    "            vmax += 1\n",
    "        if pd.isna(vmin) or pd.isna(vmax):\n",
    "             print(\"Warning: Cannot determine color range for combined plot due to NaN GAP values.\")\n",
    "             vmin, vmax = -100, 100 # Default range\n",
    "\n",
    "        norm = mcolors.TwoSlopeNorm(vmin=vmin, vcenter=0, vmax=vmax) # Center color map at 0\n",
    "        cmap = cm.coolwarm\n",
    "\n",
    "        # Define categorical types\n",
    "        df_merged['algorithm'] = pd.Categorical(df_merged['algorithm'], categories=sorted(df_merged['algorithm'].unique()), ordered=True)\n",
    "        df_merged['user_group'] = pd.Categorical(df_merged['user_group'], categories=['low', 'med', 'high'], ordered=True)\n",
    "\n",
    "        g = sns.catplot(\n",
    "            data=df_merged,\n",
    "            x='algorithm',\n",
    "            y='value_ndcg',\n",
    "            hue='user_group',\n",
    "            col='eval_strategy_desc',\n",
    "            row='pop_notion_desc',\n",
    "            kind='bar',\n",
    "            sharey=False,\n",
    "            aspect=1.5,\n",
    "            height=4,\n",
    "            palette='viridis', # Base palette (will be overridden)\n",
    "            errorbar=None,\n",
    "            # order=sorted(df_merged['algorithm'].unique()), # Redundant\n",
    "            # hue_order=['low', 'med', 'high'], # Redundant\n",
    "            legend=False # Turn off default legend\n",
    "        )\n",
    "        g.fig.suptitle('Combined Metric: Bar=NDCG@10, Color=%Î”GAP', y=1.05)\n",
    "        g.set_axis_labels(\"Algorithm\", \"NDCG@10\")\n",
    "        g.set_titles(row_template=\"{row_name}\", col_template=\"{col_name}\")\n",
    "\n",
    "        # Iterate through axes to set bar colors based on GAP\n",
    "        for ax in g.axes.flat:\n",
    "            patches = [p for p in ax.patches if isinstance(p, plt.Rectangle)] # Get bar patches\n",
    "            algo_order = sorted(df_merged['algorithm'].cat.categories)\n",
    "            hue_order = sorted(df_merged['user_group'].cat.categories)\n",
    "            num_hues = len(hue_order)\n",
    "            num_algos = len(algo_order)\n",
    "\n",
    "            if len(patches) != num_algos * num_hues:\n",
    "                print(f\"Warning: Patch/Bar mismatch in combined plot facet '{ax.get_title()}'. Skipping color update.\")\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                title_parts = ax.get_title().split(' | ')\n",
    "                current_notion = title_parts[0].split(' = ')[1]\n",
    "                current_strategy = title_parts[1].split(' = ')[1]\n",
    "                # Infer domain from data shown in this axes\n",
    "                # This relies on catplot using the filtered data for each axes\n",
    "                # A potentially fragile way is to get the domain from the first bar's data\n",
    "                # A safer way requires passing domain info explicitly\n",
    "                # Let's assume the domain is consistent within the df_merged passed to *this call*\n",
    "                current_domain = df_merged['domain'].unique()[0] # Assumes single domain if not faceted by it\n",
    "\n",
    "                for i, patch in enumerate(patches):\n",
    "                    algo_index = i // num_hues\n",
    "                    hue_index = i % num_hues\n",
    "                    current_algo = algo_order[algo_index]\n",
    "                    current_user_group = hue_order[hue_index]\n",
    "\n",
    "                    gap_val_series = df_merged[\n",
    "                        (df_merged['algorithm'] == current_algo) &\n",
    "                        (df_merged['user_group'] == current_user_group) &\n",
    "                        (df_merged['pop_notion_desc'] == current_notion) &\n",
    "                        (df_merged['eval_strategy_desc'] == current_strategy) &\n",
    "                        (df_merged['domain'] == current_domain)\n",
    "                    ]['value_gap']\n",
    "\n",
    "                    if not gap_val_series.empty:\n",
    "                        gap_val = gap_val_series.iloc[0]\n",
    "                        if pd.notna(gap_val):\n",
    "                            patch.set_facecolor(cmap(norm(gap_val)))\n",
    "                        else:\n",
    "                            patch.set_facecolor('grey') # Color for missing GAP data\n",
    "                    else:\n",
    "                         patch.set_facecolor('lightgrey') # Color if data lookup fails\n",
    "\n",
    "            except Exception as e:\n",
    "                 print(f\"Error setting colors in combined plot for facet '{ax.get_title()}': {e}\")\n",
    "\n",
    "        # Add a colorbar manually\n",
    "        try:\n",
    "            sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "            sm.set_array([]) # You need this for the colorbar to work\n",
    "            cbar = g.fig.colorbar(sm, ax=g.axes.ravel().tolist(), shrink=0.75, aspect=30, pad=0.1)\n",
    "            cbar.set_label('%Î”GAP')\n",
    "        except Exception as e:\n",
    "            print(f\"Error adding colorbar to combined plot: {e}\")\n",
    "\n",
    "        g.tick_params(axis='x', rotation=45)\n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.98]) # Adjust layout for title and colorbar\n",
    "        filepath = os.path.join(OUTPUT_DIR, f'{filename_prefix}_combined_metric.png')\n",
    "        plt.savefig(filepath, bbox_inches='tight')\n",
    "        print(f\"Saved combined metric plot to {filepath}\")\n",
    "        # plt.show()\n",
    "        plt.close(g.fig)\n",
    "    except Exception as e:\n",
    "         print(f\"Error generating combined metric plot: {e}\")\n",
    "\n",
    "\n",
    "def generate_algorithm_rankings(df_gap_diff, df_ndcg, scenario_filter, rank_metric, ascending, filename_prefix):\n",
    "    \"\"\"Generates and saves algorithm rankings based on a specific metric and scenario.\"\"\"\n",
    "    ranking_data = pd.Series(dtype=float)\n",
    "    ylabel = \"Unknown Metric\"\n",
    "\n",
    "    # Apply scenario filter\n",
    "    df_gap_scenario = df_gap_diff.copy()\n",
    "    df_ndcg_scenario = df_ndcg.copy()\n",
    "    if scenario_filter:\n",
    "        for col, val in scenario_filter.items():\n",
    "            if col in df_gap_scenario.columns:\n",
    "                df_gap_scenario = df_gap_scenario[df_gap_scenario[col] == val]\n",
    "            if col in df_ndcg_scenario.columns:\n",
    "                df_ndcg_scenario = df_ndcg_scenario[df_ndcg_scenario[col] == val]\n",
    "\n",
    "    if rank_metric == 'Abs_GAP_Fairness_Gap':\n",
    "        if 'GAP_Fairness_Gap' not in df_gap_scenario.columns or df_gap_scenario.empty:\n",
    "             print(f\"Skipping ranking by {rank_metric} for {scenario_filter}: Missing data.\")\n",
    "             return\n",
    "        df_gap_scenario['Abs_GAP_Fairness_Gap'] = df_gap_scenario['GAP_Fairness_Gap'].abs()\n",
    "        # Average rank across remaining facets (e.g., notions if not filtered)\n",
    "        ranking_data = df_gap_scenario.groupby('algorithm')['Abs_GAP_Fairness_Gap'].mean().sort_values(ascending=ascending)\n",
    "        ylabel = \"Avg. Absolute %Î”GAP Fairness Gap (Niche - Blockbuster)\"\n",
    "    elif rank_metric == 'NDCG_Niche':\n",
    "        df_ndcg_niche = df_ndcg_scenario[df_ndcg_scenario['conceptual_group'] == 'Niche-Oriented']\n",
    "        if 'value_ndcg' not in df_ndcg_niche.columns or df_ndcg_niche.empty:\n",
    "             print(f\"Skipping ranking by {rank_metric} for {scenario_filter}: Missing data.\")\n",
    "             return\n",
    "        ranking_data = df_ndcg_niche.groupby('algorithm')['value_ndcg'].mean().sort_values(ascending=ascending)\n",
    "        ylabel = \"Avg. NDCG@10 for Niche-Oriented Users\"\n",
    "    else:\n",
    "        print(f\"Unknown ranking metric: {rank_metric}\")\n",
    "        return\n",
    "\n",
    "    if ranking_data.empty:\n",
    "        print(f\"Skipping ranking plot/table for {rank_metric} - no ranking data generated.\")\n",
    "        return\n",
    "\n",
    "    # --- Create Table ---\n",
    "    ranking_table = pd.DataFrame(ranking_data)\n",
    "    ranking_table.columns = [ylabel]\n",
    "    ranking_table['Rank'] = range(1, len(ranking_table) + 1)\n",
    "    ranking_table_filename = os.path.join(OUTPUT_DIR, f'{filename_prefix}_ranking_{rank_metric}.csv')\n",
    "    ranking_table.to_csv(ranking_table_filename)\n",
    "    scenario_str = ', '.join([f'{k}={v}' for k, v in scenario_filter.items()]) if scenario_filter else 'Overall'\n",
    "    print(f\"\\n--- Algorithm Ranking ({rank_metric}) for Scenario: {scenario_str} ---\")\n",
    "    # display(ranking_table) # Use if in notebook\n",
    "    print(ranking_table)\n",
    "    print(f\"Saved ranking table to {ranking_table_filename}\")\n",
    "\n",
    "    # --- Create Plot ---\n",
    "    try:\n",
    "      plt.figure(figsize=(10, 6))\n",
    "      sns.barplot(x=ranking_data.index, y=ranking_data.values, palette='rocket', order=ranking_data.index)\n",
    "      plt.ylabel(ylabel)\n",
    "      plt.xlabel(\"Algorithm\")\n",
    "      plt.title(f\"Algorithm Ranking by {rank_metric}\\nScenario: {scenario_str}\")\n",
    "      plt.xticks(rotation=45, ha='right')\n",
    "      plt.tight_layout()\n",
    "      filepath = os.path.join(OUTPUT_DIR, f'{filename_prefix}_ranking_{rank_metric}_bar.png')\n",
    "      plt.savefig(filepath)\n",
    "      print(f\"Saved ranking plot to {filepath}\")\n",
    "      # plt.show()\n",
    "      plt.close()\n",
    "    except Exception as e:\n",
    "       print(f\"Error generating ranking plot for {rank_metric}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from consolidated_results.csv...\n",
      "Successfully loaded 864 rows.\n",
      "\n",
      "--- Data Info ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 864 entries, 0 to 863\n",
      "Data columns (total 9 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   domain               864 non-null    object \n",
      " 1   evaluation_strategy  864 non-null    object \n",
      " 2   popularity_notion    864 non-null    object \n",
      " 3   algorithm            864 non-null    object \n",
      " 4   metric_type          864 non-null    object \n",
      " 5   user_group           432 non-null    object \n",
      " 6   comparison_group     432 non-null    object \n",
      " 7   value                432 non-null    float64\n",
      " 8   p_value              432 non-null    float64\n",
      "dtypes: float64(2), object(7)\n",
      "memory usage: 60.9+ KB\n",
      "\n",
      "--- Data Head ---\n",
      "  domain evaluation_strategy popularity_notion algorithm metric_type user_group comparison_group     value  p_value\n",
      "0  music             eva_two           pop_one   MostPop        NDCG        low              NaN  0.639581      NaN\n",
      "1  music             eva_two           pop_one   UserKNN        NDCG        low              NaN  0.646007      NaN\n",
      "2  music             eva_two           pop_one   ItemKNN        NDCG        low              NaN  0.632591      NaN\n",
      "3  music             eva_two           pop_one       PMF        NDCG        low              NaN  0.642588      NaN\n",
      "4  music             eva_two           pop_one       NMF        NDCG        low              NaN  0.636150      NaN\n",
      "\n",
      "Preprocessing data...\n",
      "Dropped 432 rows due to NaN in 'value' column.\n",
      "Preprocessing complete.\n",
      "\n",
      "--- Processed Data Head (GAP) ---\n",
      "   domain evaluation_strategy popularity_notion algorithm metric_type user_group comparison_group       value  p_value eval_strategy_desc    pop_notion_desc conceptual_group\n",
      "18  music             eva_two           pop_one   MostPop         GAP        low              NaN  191.078957      NaN           UserTest  PopularPercentage   Niche-Oriented\n",
      "19  music             eva_two           pop_one   UserKNN         GAP        low              NaN   21.326975      NaN           UserTest  PopularPercentage   Niche-Oriented\n",
      "20  music             eva_two           pop_one   ItemKNN         GAP        low              NaN   -0.285377      NaN           UserTest  PopularPercentage   Niche-Oriented\n",
      "21  music             eva_two           pop_one       PMF         GAP        low              NaN   57.172554      NaN           UserTest  PopularPercentage   Niche-Oriented\n",
      "22  music             eva_two           pop_one       NMF         GAP        low              NaN   14.846776      NaN           UserTest  PopularPercentage   Niche-Oriented\n",
      "\n",
      "--- Processed Data Head (NDCG) ---\n",
      "  domain evaluation_strategy popularity_notion algorithm metric_type user_group comparison_group     value  p_value eval_strategy_desc    pop_notion_desc conceptual_group\n",
      "0  music             eva_two           pop_one   MostPop        NDCG        low              NaN  0.639581      NaN           UserTest  PopularPercentage   Niche-Oriented\n",
      "1  music             eva_two           pop_one   UserKNN        NDCG        low              NaN  0.646007      NaN           UserTest  PopularPercentage   Niche-Oriented\n",
      "2  music             eva_two           pop_one   ItemKNN        NDCG        low              NaN  0.632591      NaN           UserTest  PopularPercentage   Niche-Oriented\n",
      "3  music             eva_two           pop_one       PMF        NDCG        low              NaN  0.642588      NaN           UserTest  PopularPercentage   Niche-Oriented\n",
      "4  music             eva_two           pop_one       NMF        NDCG        low              NaN  0.636150      NaN           UserTest  PopularPercentage   Niche-Oriented\n"
     ]
    }
   ],
   "source": [
    "# 1. Load Data\n",
    "print(f\"Loading data from {CSV_FILE_PATH}...\")\n",
    "try:\n",
    "    df = pd.read_csv(CSV_FILE_PATH)\n",
    "    print(f\"Successfully loaded {len(df)} rows.\")\n",
    "    # Display basic info and head\n",
    "    print(\"\\n--- Data Info ---\")\n",
    "    df.info()\n",
    "    print(\"\\n--- Data Head ---\")\n",
    "    print(df.head())\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: CSV file not found at {CSV_FILE_PATH}\")\n",
    "    # Exit or handle appropriately in a real script\n",
    "    # For notebook, we can just stop execution of subsequent cells\n",
    "    raise # Stop notebook execution here\n",
    "\n",
    "# 2. Preprocess Data\n",
    "print(\"\\nPreprocessing data...\")\n",
    "df['value'] = pd.to_numeric(df['value'], errors='coerce')\n",
    "df['p_value'] = pd.to_numeric(df['p_value'], errors='coerce')\n",
    "\n",
    "# Apply descriptive names\n",
    "df = map_descriptive_names(df)\n",
    "\n",
    "# Add conceptual group mapping\n",
    "df['conceptual_group'] = df.apply(map_conceptual_group, axis=1)\n",
    "\n",
    "# Drop rows where the primary metric value is NaN, as they can't be plotted/analyzed\n",
    "initial_rows = len(df)\n",
    "df.dropna(subset=['value'], inplace=True)\n",
    "if initial_rows > len(df):\n",
    "    print(f\"Dropped {initial_rows - len(df)} rows due to NaN in 'value' column.\")\n",
    "\n",
    "# Separate DataFrames for metrics and t-tests\n",
    "df_gap = df[df['metric_type'] == 'GAP'].copy()\n",
    "df_ndcg = df[df['metric_type'] == 'NDCG'].copy()\n",
    "df_gap_ttest = df[df['metric_type'] == 'GAP_TTEST'].copy()\n",
    "df_ndcg_ttest = df[df['metric_type'] == 'NDCG_TTEST'].copy()\n",
    "\n",
    "print(\"Preprocessing complete.\")\n",
    "print(\"\\n--- Processed Data Head (GAP) ---\")\n",
    "print(df_gap.head())\n",
    "print(\"\\n--- Processed Data Head (NDCG) ---\")\n",
    "print(df_ndcg.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Base Analysis: %Î”GAP and NDCG@10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 %Î”GAP Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Generating %Î”GAP Analysis (Base Plots & Tables) ---\n",
      "\n",
      "Plotting Faceted %Î”GAP for domain: music\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreyash\\AppData\\Local\\Temp\\ipykernel_26416\\3073107835.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['algorithm'] = pd.Categorical(data['algorithm'], categories=sorted(data['algorithm'].unique()), ordered=True)\n",
      "C:\\Users\\Shreyash\\AppData\\Local\\Temp\\ipykernel_26416\\3073107835.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['user_group'] = pd.Categorical(data['user_group'], categories=['low', 'med', 'high'], ordered=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved faceted bar chart to analysis_plots_tables_v2\\music_gap_value_faceted.png\n",
      "\n",
      "Plotting Faceted %Î”GAP for domain: movies\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreyash\\AppData\\Local\\Temp\\ipykernel_26416\\3073107835.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['algorithm'] = pd.Categorical(data['algorithm'], categories=sorted(data['algorithm'].unique()), ordered=True)\n",
      "C:\\Users\\Shreyash\\AppData\\Local\\Temp\\ipykernel_26416\\3073107835.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['user_group'] = pd.Categorical(data['user_group'], categories=['low', 'med', 'high'], ordered=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved faceted bar chart to analysis_plots_tables_v2\\movies_gap_value_faceted.png\n",
      "\n",
      "Plotting Comparative %Î”GAP by Popularity Notion...\n",
      "Saved comparative bar chart to analysis_plots_tables_v2\\gap_compare_value_compare_Niche-Oriented.png\n",
      "Saved comparative bar chart to analysis_plots_tables_v2\\gap_compare_value_compare_Diverse.png\n",
      "Saved comparative bar chart to analysis_plots_tables_v2\\gap_compare_value_compare_Blockbuster-Oriented.png\n",
      "\n",
      "--- Summary Table: value --- created (saving to file).\n",
      "Saved table to analysis_plots_tables_v2\\summary_table_gap.csv\n",
      "Skipping t-test table ttest_table_gap.csv - no data.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Generating %Î”GAP Analysis (Base Plots & Tables) ---\")\n",
    "\n",
    "# Faceted Bar Chart (%Î”GAP by User Group within notion/strategy)\n",
    "for domain in df_gap['domain'].unique():\n",
    "    print(f\"\\nPlotting Faceted %Î”GAP for domain: {domain}\")\n",
    "    plot_faceted_grouped_bar(\n",
    "        df_gap[df_gap['domain'] == domain],\n",
    "        'value',\n",
    "        f'%Î”GAP ({domain})',\n",
    "        f'{domain}_gap'\n",
    "    )\n",
    "\n",
    "# Comparative Bar Chart (%Î”GAP by Pop Notion for conceptual groups)\n",
    "print(\"\\nPlotting Comparative %Î”GAP by Popularity Notion...\")\n",
    "plot_comparative_grouped_bar(\n",
    "    df_gap,\n",
    "    'value',\n",
    "    '%Î”GAP Comparison',\n",
    "    'gap_compare'\n",
    ")\n",
    "\n",
    "# Summary Table (%Î”GAP)\n",
    "gap_summary_table = create_summary_table(df_gap, 'value', 'summary_table_gap.csv')\n",
    "\n",
    "# T-test Table (%Î”GAP)\n",
    "gap_ttest_table = create_ttest_table(df_gap_ttest, 'ttest_table_gap.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 NDCG@10 Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Generating NDCG@10 Analysis (Base Plots & Tables) ---\n",
      "\n",
      "Plotting Faceted NDCG@10 for domain: music\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreyash\\AppData\\Local\\Temp\\ipykernel_26416\\3073107835.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['algorithm'] = pd.Categorical(data['algorithm'], categories=sorted(data['algorithm'].unique()), ordered=True)\n",
      "C:\\Users\\Shreyash\\AppData\\Local\\Temp\\ipykernel_26416\\3073107835.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['user_group'] = pd.Categorical(data['user_group'], categories=['low', 'med', 'high'], ordered=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved faceted bar chart to analysis_plots_tables_v2\\music_ndcg_value_faceted.png\n",
      "\n",
      "Plotting Faceted NDCG@10 for domain: movies\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreyash\\AppData\\Local\\Temp\\ipykernel_26416\\3073107835.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['algorithm'] = pd.Categorical(data['algorithm'], categories=sorted(data['algorithm'].unique()), ordered=True)\n",
      "C:\\Users\\Shreyash\\AppData\\Local\\Temp\\ipykernel_26416\\3073107835.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['user_group'] = pd.Categorical(data['user_group'], categories=['low', 'med', 'high'], ordered=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved faceted bar chart to analysis_plots_tables_v2\\movies_ndcg_value_faceted.png\n",
      "\n",
      "Plotting Comparative NDCG@10 by Popularity Notion...\n",
      "Saved comparative bar chart to analysis_plots_tables_v2\\ndcg_compare_value_compare_Niche-Oriented.png\n",
      "Saved comparative bar chart to analysis_plots_tables_v2\\ndcg_compare_value_compare_Diverse.png\n",
      "Saved comparative bar chart to analysis_plots_tables_v2\\ndcg_compare_value_compare_Blockbuster-Oriented.png\n",
      "\n",
      "--- Summary Table: value --- created (saving to file).\n",
      "Saved table to analysis_plots_tables_v2\\summary_table_ndcg.csv\n",
      "Skipping t-test table ttest_table_ndcg.csv - no data.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Generating NDCG@10 Analysis (Base Plots & Tables) ---\")\n",
    "\n",
    "# Faceted Bar Chart (NDCG by User Group within notion/strategy)\n",
    "for domain in df_ndcg['domain'].unique():\n",
    "    print(f\"\\nPlotting Faceted NDCG@10 for domain: {domain}\")\n",
    "    plot_faceted_grouped_bar(\n",
    "        df_ndcg[df_ndcg['domain'] == domain],\n",
    "        'value',\n",
    "        f'NDCG@10 ({domain})',\n",
    "        f'{domain}_ndcg'\n",
    "    )\n",
    "\n",
    "# Comparative Bar Chart (NDCG by Pop Notion for conceptual groups)\n",
    "print(\"\\nPlotting Comparative NDCG@10 by Popularity Notion...\")\n",
    "plot_comparative_grouped_bar(\n",
    "    df_ndcg,\n",
    "    'value',\n",
    "    'NDCG@10 Comparison',\n",
    "    'ndcg_compare'\n",
    ")\n",
    "\n",
    "# Summary Table (NDCG)\n",
    "ndcg_summary_table = create_summary_table(df_ndcg, 'value', 'summary_table_ndcg.csv')\n",
    "\n",
    "# T-test Table (NDCG)\n",
    "ndcg_ttest_table = create_ttest_table(df_ndcg_ttest, 'ttest_table_ndcg.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Advanced Analysis Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Scatter Plot: Bias vs. Accuracy (%Î”GAP vs. NDCG@10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Plotting %Î”GAP vs NDCG@10 scatter plot...\n",
      "Saved scatter plot to analysis_plots_tables_v2\\adv__bias_vs_accuracy_scatter.png\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nPlotting %Î”GAP vs NDCG@10 scatter plot...\")\n",
    "\n",
    "# Merge GAP and NDCG data\n",
    "df_merged_metrics = pd.merge(\n",
    "    df_gap[['domain', 'evaluation_strategy', 'popularity_notion', 'algorithm', 'user_group', 'value', 'conceptual_group', 'eval_strategy_desc', 'pop_notion_desc']],\n",
    "    df_ndcg[['domain', 'evaluation_strategy', 'popularity_notion', 'algorithm', 'user_group', 'value']],\n",
    "    on=['domain', 'evaluation_strategy', 'popularity_notion', 'algorithm', 'user_group'],\n",
    "    suffixes=('_gap', '_ndcg')\n",
    ")\n",
    "\n",
    "if not df_merged_metrics.empty:\n",
    "    plot_bias_accuracy_scatter(df_merged_metrics, 'adv_')\n",
    "else:\n",
    "    print(\"Warning: Merged dataframe for scatter plot is empty. Check input data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Delta Plots: Fairness Gaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculating and plotting Fairness Gaps...\n",
      "Saved fairness gap plot to analysis_plots_tables_v2\\adv_gap_fairness_gap.png\n",
      "Saved fairness gap plot to analysis_plots_tables_v2\\adv_ndcg_fairness_gap.png\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nCalculating and plotting Fairness Gaps...\")\n",
    "\n",
    "# Prepare data by pivoting\n",
    "df_fairness_comp = df[df['conceptual_group'].isin(['Niche-Oriented', 'Blockbuster-Oriented'])].copy()\n",
    "\n",
    "# Pivot for GAP\n",
    "pivot_gap_fairness = df_fairness_comp[df_fairness_comp['metric_type']=='GAP'].pivot_table(\n",
    "    index=['domain', 'eval_strategy_desc', 'pop_notion_desc', 'algorithm'],\n",
    "    columns='conceptual_group',\n",
    "    values='value'\n",
    ").reset_index()\n",
    "\n",
    "# Pivot for NDCG\n",
    "pivot_ndcg_fairness = df_fairness_comp[df_fairness_comp['metric_type']=='NDCG'].pivot_table(\n",
    "    index=['domain', 'eval_strategy_desc', 'pop_notion_desc', 'algorithm'],\n",
    "    columns='conceptual_group',\n",
    "    values='value'\n",
    ").reset_index()\n",
    "\n",
    "# Calculate GAP difference (Niche - Blockbuster)\n",
    "if 'Niche-Oriented' in pivot_gap_fairness.columns and 'Blockbuster-Oriented' in pivot_gap_fairness.columns:\n",
    "    pivot_gap_fairness['GAP_Fairness_Gap'] = pivot_gap_fairness['Niche-Oriented'] - pivot_gap_fairness['Blockbuster-Oriented']\n",
    "    plot_fairness_gap(pivot_gap_fairness.dropna(subset=['GAP_Fairness_Gap']), 'GAP_Fairness_Gap', '%Î”GAP Diff (Niche - Blockbuster)', '%Î”GAP', 'adv_gap')\n",
    "else:\n",
    "    print(\"Warning: Cannot calculate GAP Fairness Gap - missing Niche or Blockbuster groups in pivot.\")\n",
    "    # Assign empty df to avoid error later if needed for ranking\n",
    "    pivot_gap_fairness['GAP_Fairness_Gap'] = np.nan \n",
    "\n",
    "# Calculate NDCG difference (Blockbuster - Niche)\n",
    "if 'Niche-Oriented' in pivot_ndcg_fairness.columns and 'Blockbuster-Oriented' in pivot_ndcg_fairness.columns:\n",
    "    pivot_ndcg_fairness['NDCG_Fairness_Gap'] = pivot_ndcg_fairness['Blockbuster-Oriented'] - pivot_ndcg_fairness['Niche-Oriented'] # Higher is better for Blockbuster\n",
    "    plot_fairness_gap(pivot_ndcg_fairness.dropna(subset=['NDCG_Fairness_Gap']), 'NDCG_Fairness_Gap', 'NDCG@10 Diff (Blockbuster - Niche)', 'NDCG@10', 'adv_ndcg')\n",
    "else:\n",
    "     print(\"Warning: Cannot calculate NDCG Fairness Gap - missing Niche or Blockbuster groups in pivot.\")\n",
    "     pivot_ndcg_fairness['NDCG_Fairness_Gap'] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Delta Plots: Evaluation Strategy Impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculating and plotting Evaluation Strategy Impact...\n",
      "Saved strategy impact plot to analysis_plots_tables_v2\\adv_gap_strategy_impact.png\n",
      "Saved strategy impact plot to analysis_plots_tables_v2\\adv_ndcg_strategy_impact.png\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nCalculating and plotting Evaluation Strategy Impact...\")\n",
    "\n",
    "# Pivot GAP data by strategy\n",
    "pivot_gap_strategy = df_gap.pivot_table(\n",
    "    index=['domain', 'pop_notion_desc', 'algorithm', 'conceptual_group'],\n",
    "    columns='eval_strategy_desc',\n",
    "    values='value'\n",
    ").reset_index()\n",
    "\n",
    "# Pivot NDCG data by strategy\n",
    "pivot_ndcg_strategy = df_ndcg.pivot_table(\n",
    "    index=['domain', 'pop_notion_desc', 'algorithm', 'conceptual_group'],\n",
    "    columns='eval_strategy_desc',\n",
    "    values='value'\n",
    ").reset_index()\n",
    "\n",
    "# Calculate GAP difference (TrainItems - UserTest)\n",
    "if 'TrainItems' in pivot_gap_strategy.columns and 'UserTest' in pivot_gap_strategy.columns:\n",
    "    pivot_gap_strategy['GAP_Strategy_Diff'] = pivot_gap_strategy['TrainItems'] - pivot_gap_strategy['UserTest']\n",
    "    plot_strategy_impact_delta(pivot_gap_strategy.dropna(subset=['GAP_Strategy_Diff']), 'GAP_Strategy_Diff', '%Î”GAP Diff', '%Î”GAP', 'adv_gap')\n",
    "else:\n",
    "    print(\"Warning: Cannot calculate GAP Strategy Impact - missing TrainItems or UserTest columns.\")\n",
    "    pivot_gap_strategy['GAP_Strategy_Diff'] = np.nan\n",
    "\n",
    "# Calculate NDCG difference (TrainItems - UserTest)\n",
    "if 'TrainItems' in pivot_ndcg_strategy.columns and 'UserTest' in pivot_ndcg_strategy.columns:\n",
    "    pivot_ndcg_strategy['NDCG_Strategy_Diff'] = pivot_ndcg_strategy['TrainItems'] - pivot_ndcg_strategy['UserTest']\n",
    "    plot_strategy_impact_delta(pivot_ndcg_strategy.dropna(subset=['NDCG_Strategy_Diff']), 'NDCG_Strategy_Diff', 'NDCG@10 Diff', 'NDCG@10', 'adv_ndcg')\n",
    "else:\n",
    "    print(\"Warning: Cannot calculate NDCG Strategy Impact - missing TrainItems or UserTest columns.\")\n",
    "    pivot_ndcg_strategy['NDCG_Strategy_Diff'] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Algorithm Rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating Algorithm Rankings...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'copy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 8\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Scenario 1: Rank by absolute GAP fairness gap under TrainItems using NicheConsumptionRate (averaged over domains)\u001b[39;00m\n\u001b[0;32m      4\u001b[0m filter_scen1 \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124meval_strategy_desc\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrainItems\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpop_notion_desc\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNicheConsumptionRate\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      7\u001b[0m }\n\u001b[1;32m----> 8\u001b[0m \u001b[43mgenerate_algorithm_rankings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpivot_gap_fairness\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilter_scen1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAbs_GAP_Fairness_Gap\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mascending\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43madv_rank_fairness_trainitems_pop4\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Scenario 2: Rank by NDCG for Niche users under TrainItems using NicheConsumptionRate (averaged over domains)\u001b[39;00m\n\u001b[0;32m     11\u001b[0m filter_scen2 \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124meval_strategy_desc\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrainItems\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpop_notion_desc\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNicheConsumptionRate\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;66;03m#'conceptual_group': 'Niche-Oriented' # Filter is applied inside the function\u001b[39;00m\n\u001b[0;32m     15\u001b[0m }\n",
      "Cell \u001b[1;32mIn[2], line 426\u001b[0m, in \u001b[0;36mgenerate_algorithm_rankings\u001b[1;34m(df_gap_diff, df_ndcg, scenario_filter, rank_metric, ascending, filename_prefix)\u001b[0m\n\u001b[0;32m    424\u001b[0m \u001b[38;5;66;03m# Apply scenario filter\u001b[39;00m\n\u001b[0;32m    425\u001b[0m df_gap_scenario \u001b[38;5;241m=\u001b[39m df_gap_diff\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m--> 426\u001b[0m df_ndcg_scenario \u001b[38;5;241m=\u001b[39m \u001b[43mdf_ndcg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m()\n\u001b[0;32m    427\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m scenario_filter:\n\u001b[0;32m    428\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m col, val \u001b[38;5;129;01min\u001b[39;00m scenario_filter\u001b[38;5;241m.\u001b[39mitems():\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'copy'"
     ]
    }
   ],
   "source": [
    "print(\"\\nGenerating Algorithm Rankings...\")\n",
    "\n",
    "# Scenario 1: Rank by absolute GAP fairness gap under TrainItems using NicheConsumptionRate (averaged over domains)\n",
    "filter_scen1 = {\n",
    "    'eval_strategy_desc': 'TrainItems',\n",
    "    'pop_notion_desc': 'NicheConsumptionRate'\n",
    "}\n",
    "generate_algorithm_rankings(pivot_gap_fairness, None, filter_scen1, 'Abs_GAP_Fairness_Gap', ascending=True, filename_prefix='adv_rank_fairness_trainitems_pop4')\n",
    "\n",
    "# Scenario 2: Rank by NDCG for Niche users under TrainItems using NicheConsumptionRate (averaged over domains)\n",
    "filter_scen2 = {\n",
    "    'eval_strategy_desc': 'TrainItems',\n",
    "    'pop_notion_desc': 'NicheConsumptionRate',\n",
    "    #'conceptual_group': 'Niche-Oriented' # Filter is applied inside the function\n",
    "}\n",
    "df_ndcg_niche = df_ndcg[df_ndcg['conceptual_group'] == 'Niche-Oriented'] # Pre-filter for niche users\n",
    "generate_algorithm_rankings(None, df_ndcg_niche, filter_scen2, 'NDCG_Niche', ascending=False, filename_prefix='adv_rank_accuracy_trainitems_pop4')\n",
    "\n",
    "# Add more scenarios if needed, e.g., filtering by domain:\n",
    "# filter_scen3 = {\n",
    "#     'domain': 'music',\n",
    "#     'eval_strategy_desc': 'TrainItems',\n",
    "#     'pop_notion_desc': 'NicheConsumptionRate'\n",
    "# }\n",
    "# generate_algorithm_rankings(pivot_gap_fairness, None, filter_scen3, 'Abs_GAP_Fairness_Gap', ascending=True, filename_prefix='adv_rank_fairness_trainitems_pop4_music')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 Combined Metric Plot (Experimental)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"\\nGenerating Combined Metric Plot (Bar=NDCG, Color=%Î”GAP)...\")\n",
    "# # This plot can be complex and might require adjustments\n",
    "# if not df_merged_metrics.empty:\n",
    "#     # May need to filter df_merged_metrics further if generating per-domain plots\n",
    "#     plot_combined_metric_bar(df_merged_metrics, 'adv_') \n",
    "# else:\n",
    "#     print(\"Skipping Combined Metric plot - merged data empty.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Analysis Complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n--- Analysis Script Finished. Plots and tables saved to '{OUTPUT_DIR}' directory. ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
